{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddedDllDirectory('C:\\\\Program Files\\\\CoppeliaRobotics\\\\CoppeliaSimEdu')>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "''''''\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from keras import Model\n",
    "\n",
    "import random\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from keras.models import load_model\n",
    "from numpy.random import seed\n",
    "\n",
    "# seed(1)\n",
    "# tf.random.set_seed(1)\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import os\n",
    "os.add_dll_directory(r'C:\\Program Files\\CoppeliaRobotics\\CoppeliaSimEdu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input     = 8 + 8 + 2\n",
    "n_output    = 8\n",
    "n_q_input   = n_input + n_output\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "num_obj         = 50\n",
    "cycle           = 200\n",
    "num_point       = 25\n",
    "max_period      = 999\n",
    "gamma           = 0.99\n",
    "lvl_noise       = 40\n",
    "\n",
    "a_min           = 10\n",
    "a_max           = 40\n",
    "\n",
    "dt              = 5\n",
    "da              = 20\n",
    "\n",
    "phi_max         = 2 / 1300\n",
    "phi_min         = 0.5 / 1300\n",
    "\n",
    "theta_max       = 2 * math.pi\n",
    "theta_min       = 0\n",
    "\n",
    "maxTime = 13\n",
    "minTime = 8\n",
    "\n",
    "phi = [\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    ]\n",
    "a = [\n",
    "    25,\n",
    "    25,\n",
    "    25,\n",
    "    25,\n",
    "    20,\n",
    "    20,\n",
    "    20,\n",
    "    20\n",
    "    ]\n",
    "theta = [\n",
    "    3 * math.pi / 2,\n",
    "    3 * math.pi / 2,\n",
    "    math.pi / 2, \n",
    "    math.pi / 2, \n",
    "    0,\n",
    "    math.pi,\n",
    "    math.pi,\n",
    "    0,\n",
    "    ]\n",
    "legs_name = [\n",
    "    'JTopRight2',\n",
    "    'JTopRight1',\n",
    "    'JTopLeft2' ,\n",
    "    'JTopLeft1' ,\n",
    "    'JBotRight2',\n",
    "    'JBotRight1',\n",
    "    'JBotLeft2' ,\n",
    "    'JBotLeft1' \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_s_a\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 18)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 152       \n",
      "=================================================================\n",
      "Total params: 836\n",
      "Trainable params: 836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_state =       Input(shape=(n_input,))\n",
    "x1 =                 Dense(18, activation='sigmoid')         (input_state)\n",
    "x2 =                 Dense(18, activation='sigmoid')         (x1)\n",
    "output_action =     Dense(n_output, activation='sigmoid')   (x2)\n",
    "\n",
    "model_s_a = Model(inputs = input_state, outputs = output_action, name=\"model_s_a\")\n",
    "model_s_a.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae']) \n",
    "\n",
    "model_s_a.summary()\n",
    "model_s_a.run_eagerly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_sa_q\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 26)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 27        \n",
      "=================================================================\n",
      "Total params: 1,431\n",
      "Trainable params: 1,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_state =       Input(shape=(n_q_input,))\n",
    "x1 =                 Dense(26, activation='sigmoid') (input_state)\n",
    "x2 =                 Dense(26, activation='sigmoid') (x1)\n",
    "output_action =     Dense(1, activation='sigmoid')  (x2)\n",
    "\n",
    "model_sa_q = Model(inputs = input_state, outputs = output_action, name = \"model_sa_q\")\n",
    "model_sa_q.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae']) \n",
    "\n",
    "model_sa_q.summary()\n",
    "model_sa_q.run_eagerly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leg:\n",
    "    def __init__(self,inputHand):\n",
    "        self.Hand = inputHand\n",
    "        self.vel = 0\n",
    "        self.pos = 0\n",
    "    def eventPos(self,msg):\n",
    "        global startFlag\n",
    "        if startFlag:\n",
    "            self.vel = 0\n",
    "            startFlag = False\n",
    "        else:\n",
    "            self.vel = (msg[1] - self.pos)/dtSimTime\n",
    "        self.pos = msg[1]\n",
    "        \n",
    "        \n",
    "class Body:\n",
    "    def __init__(self,inputHand):\n",
    "        self.Hand = inputHand\n",
    "        self.pos = [0,0,0,0,0,0,1]\n",
    "    def eventPos(self,msg):\n",
    "        self.pos = msg[1]\n",
    "\n",
    "def discount_rewards(r):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = []\n",
    "    running_add = 0\n",
    "    for t in reversed(range(0, r.size)):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r.append(np.array([running_add]))\n",
    "    return np.array(discounted_r)\n",
    "def negative5(arr):\n",
    "    ans = [arr[3],arr[2],arr[1],arr[0],-arr[4]]\n",
    "    return ans\n",
    "def negative8(arr):\n",
    "    ans = [arr[3],arr[2],arr[1],arr[0],arr[3+4],arr[2+4],arr[1+4],arr[0+4]]\n",
    "    return ans\n",
    "def action_to_param_sin(action):\n",
    "    phi         = []\n",
    "    a           = []\n",
    "    theta       = []\n",
    "    for i in range(3 * 8):\n",
    "        noise = random.random() * 100\n",
    "        if noise < lvl_noise:\n",
    "            action[i] = random.randint(0,1)\n",
    "    for i in range(0, 3 * 8, 3):\n",
    "        phi.append(action[i] * (phi_max - phi_min) + phi_min)\n",
    "        a.append(action[i+1] * (a_max - a_min) + a_min)\n",
    "        theta.append(action[i+2] * (theta_max - theta_min) + theta_min)\n",
    "    return phi,a,theta\n",
    "def Reward(real_time,pos):\n",
    "    stop = False\n",
    "    s = pos[1]\n",
    "    err = pos[0]\n",
    "    angle_err = abs(pos[5])\n",
    "    angle_flip = abs(pos[3]) + abs(pos[4])\n",
    "    reward = 1\n",
    "    if s >= 1:\n",
    "        reward = 1\n",
    "        stop = True\n",
    "        print(\"-1-\")\n",
    "        return reward,stop\n",
    "    if real_time > maxTime:\n",
    "        reward = 0\n",
    "        stop = True\n",
    "        print(\"-2-\")\n",
    "        return reward,stop\n",
    "    if err > 0.1:\n",
    "        reward = 0\n",
    "        stop = True\n",
    "        print(\"-3-\")\n",
    "        return reward,stop\n",
    "    if angle_err > 0.6:\n",
    "        reward = 0\n",
    "        stop = True\n",
    "        print(\"-4-\")\n",
    "        return reward,stop\n",
    "    if angle_flip > 0.9:\n",
    "        reward = 0\n",
    "        stop = True\n",
    "        print(\"-5-\")\n",
    "        return reward,stop\n",
    "    if s < -0.1:\n",
    "        reward = 0\n",
    "        stop = True\n",
    "        print(\"-6-\",pos)\n",
    "        return reward,stop\n",
    "    return reward,stop\n",
    "def simTrain(real_time,state,key,client):\n",
    "    if key == \"sin\":\n",
    "        x = []\n",
    "        for i in range(0,4):\n",
    "            noise = random.random() * 3\n",
    "            x.append(17 * math.sin(phi[i] * (real_time + 25/1000) * 2 * math.pi + theta[i]) - 10 + noise)\n",
    "        for i in range(4,8):\n",
    "            noise = random.random() * 5\n",
    "            x.append(17 * math.sin(phi[i] * (real_time + 25/1000) * 2 * math.pi + theta[i]) - 20 + noise)\n",
    "    if key == \"neuron\":\n",
    "        global model_s_a\n",
    "        global legs\n",
    "        action = model_s_a.predict(np.array([state]))[0]\n",
    "        print(action)\n",
    "        x = []\n",
    "        for i in range(0,4):\n",
    "            noise = random.random()\n",
    "            x.append(( (action[i] + (noise - action[i]) * 0.2) * 2 - 1) * 20 - 10)\n",
    "        for i in range(4,8):\n",
    "            noise = random.random()\n",
    "            x.append(( (action[i] + (noise - action[i]) * 0.2) * 2 - 1) * 20 - 20)\n",
    "    joint_value = [-x[0],x[1],x[2],-x[3],x[4],x[5],x[6],x[7]]\n",
    "    for i in range(8):\n",
    "        client.simxSetJointTargetPosition(legs[i].Hand,joint_value[i] / 180 * math.pi,client.simxDefaultPublisher())\n",
    "    return x\n",
    "def simVerify(real_time,state,client):\n",
    "    action = model_s_a.predict(np.array([state]))[0]\n",
    "    x = []\n",
    "    for i in range(0,4):\n",
    "        x.append((action[i] * 2 - 1) * 20 - 10)\n",
    "    for i in range(4,8):\n",
    "        x.append((action[i] * 2 - 1) * 20 - 20)\n",
    "    joint_value = [-x[0],x[1],x[2],-x[3],x[4],x[5],x[6],x[7]]\n",
    "    for i in range(8):\n",
    "        client.simxSetJointTargetPosition(legs[i].Hand,joint_value[i] / 180 * math.pi,client.simxDefaultPublisher())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeArray = []\n",
    "sArray = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_s_a.save(\"model_s_a_MOTHERFUCKER.h5\")\n",
    "# model_sa_q.save(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_s_a = load_model(\"model_s_a_MOTHERFUCKER.h5\")\n",
    "# model_sa_q = load_model(\"model_sa_qV3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты:\n",
      "Время -  []\n",
      "Расстояние -  []\n",
      "N =  1  Испытание  2  из 50\n",
      "sin\n",
      "\n",
      "  Running B0 Remote API client with channel name [b0RemoteApi_q_robot]\n",
      "  make sure that: 1) the B0 resolver is running\n",
      "                  2) CoppeliaSim is running the B0 Remote API server with the same channel name\n",
      "  Initializing...\n",
      "\n",
      "\n",
      "  Connected!\n",
      "\n",
      "-4-\n",
      "286\n",
      "*************************************************************************************\n",
      "** Leaving... if this is unexpected, you might have to adjust the timeout argument **\n",
      "*************************************************************************************\n",
      "=YYEEESS=\n",
      "687 26\n",
      "687 1\n"
     ]
    }
   ],
   "source": [
    "for exp in range(1):\n",
    "    global train_output\n",
    "    global train_input\n",
    "    train_input     = np.array([])\n",
    "    train_output    = np.array([])\n",
    "# начало испытаний ==============================================================================================\n",
    "    for j in range(2):\n",
    "\n",
    "        clear_output()\n",
    "        print(\"Результаты:\")\n",
    "        print(\"Время - \",timeArray)\n",
    "        print(\"Расстояние - \",sArray)\n",
    "        print(\"N = \",exp + 1,\" Испытание \",j + 1,\" из 50\")\n",
    "\n",
    "        \n",
    "\n",
    "# ОБУЧЕНИЕ RL СЕТИ ==============================================================================================\n",
    "        def Learn():\n",
    "            \n",
    "            import SimLibB0.b0RemoteApi as b0RemoteApi    \n",
    "            global train_output\n",
    "            global train_input\n",
    "            global reward\n",
    "            global dtSimTime\n",
    "            global lastSimTime\n",
    "            global startFlag\n",
    "            global doNextStep\n",
    "            global stop\n",
    "            global body\n",
    "            global legs\n",
    "            lllll = 0\n",
    "            temp = exp\n",
    "            if exp > 50:\n",
    "                temp = 50\n",
    "            if random.random() < (1 - temp/50 * 0.5):\n",
    "                key = \"sin\"\n",
    "                print(\"sin\")\n",
    "            else:\n",
    "                key = \"neuron\"\n",
    "                print(\"neuron\")\n",
    "            reward = []\n",
    "            dtSimTime = 0.025\n",
    "            lastSimTime = 0\n",
    "            startFlag = True\n",
    "            with b0RemoteApi.RemoteApiClient('b0RemoteApi_pythonClient'+str(exp*50 + j),'b0RemoteApi_q_robot') as client:\n",
    "                doNextStep = True\n",
    "                stop = False\n",
    "            # -------------------------------------------------------------------------------------------------------\n",
    "                def simulationStepStarted(msg):\n",
    "                    \n",
    "                    simTime = msg[1][b'simulationTime']\n",
    "                    global legs\n",
    "                    global body \n",
    "                    global train_input\n",
    "                    state = np.array([])\n",
    "                    for i in range(0,4):\n",
    "                        state  = np.append(state, (legs[i].pos + 10) / (40) + 0.5)\n",
    "                        state  = np.append(state, legs[i].vel / (600 * 2) + 0.5)\n",
    "                    for i in range(4,8):\n",
    "                        state  = np.append(state, (legs[i].pos + 20) / (40) + 0.5 )\n",
    "                        state  = np.append(state, legs[i].vel / (600 * 2) + 0.5)\n",
    "                    state = np.append(state, [body.pos[0] / 0.1,body.pos[5] / 0.6])\n",
    "                    jointAction = simTrain(simTime,state,key,client)\n",
    "\n",
    "                    action = np.array([])\n",
    "                    for i in range(0,4):\n",
    "                        action = np.append(action, (jointAction[i] + 10) / (40) + 0.5)\n",
    "                    for i in range(4,8):\n",
    "                        action = np.append(action, (jointAction[i] + 20) / (40) + 0.5)\n",
    "                    global startFlag\n",
    "                    temp = np.append(state,action)\n",
    "                    for i in range(26):\n",
    "                        if temp[i] > 1:\n",
    "                            temp[i] = 1\n",
    "                        if temp[i] < 0:\n",
    "                            temp[i] = 0\n",
    "                    if startFlag and j == 0:\n",
    "                        train_input = np.array( [temp] )\n",
    "                    else:\n",
    "                        train_input = np.concatenate( (train_input,np.array([np.append(state,action)]) ),axis = 0)\n",
    "                    \n",
    "            # -------------------------------------------------------------------------------------------------------\n",
    "                def simulationStepDone(msg):\n",
    "                    simTime = msg[1][b'simulationTime']\n",
    "                    global reward\n",
    "                    global stop\n",
    "                    global body\n",
    "                    r,stop = Reward(simTime,body.pos)\n",
    "                    reward = np.append(reward,r)\n",
    "\n",
    "                    global dtSimTime\n",
    "                    global lastSimTime\n",
    "                    dtSimTime = simTime - lastSimTime\n",
    "                    lastSimTime = simTime\n",
    "                    global doNextStep\n",
    "                    doNextStep=True\n",
    "            # -------------------------------------------------------------------------------------------------------\n",
    "                def init_hand():\n",
    "                    global body\n",
    "                    errHand,bodyHand = client.simxGetObjectHandle(\"RobotTyapa\",client.simxServiceCall())\n",
    "                    body = Body(bodyHand)\n",
    "                    # привязываем обработчик для чтения получения данных о роботе\n",
    "                    client.simxGetObjectPose(body.Hand,-1,client.simxDefaultSubscriber(body.eventPos))\n",
    "                    global legs\n",
    "                    legs = []\n",
    "                    for leg in legs_name:\n",
    "                        errHand,legHand = client.simxGetObjectHandle(leg,client.simxServiceCall())\n",
    "                        legs.append(Leg(legHand))\n",
    "                    # привязываем обработчик для чтения получения данных о движках\n",
    "                    for leg in legs:\n",
    "                        client.simxGetJointPosition(leg.Hand,client.simxDefaultSubscriber(leg.eventPos))\n",
    "            # -------------------------------------------------------------------------------------------------------\n",
    "                client.simxSynchronous(True)\n",
    "                client.simxGetSimulationStepStarted(client.simxDefaultSubscriber(simulationStepStarted))\n",
    "                client.simxGetSimulationStepDone(client.simxDefaultSubscriber(simulationStepDone))\n",
    "                client.simxStartSimulation(client.simxDefaultPublisher())\n",
    "                init_hand()\n",
    "                startTime = time.time()\n",
    "                while not(stop): \n",
    "                    if doNextStep:\n",
    "                        doNextStep = False\n",
    "                        lllll += 1\n",
    "                        client.simxSynchronousTrigger()\n",
    "                    client.simxSpinOnce()\n",
    "                client.simxStopSimulation(client.simxDefaultPublisher())\n",
    "                if body.pos[1] < 0:\n",
    "                    temp = 0\n",
    "                else:\n",
    "                    temp = body.pos[1]\n",
    "                if j == 0:\n",
    "                    train_output = discount_rewards(np.array(reward)) * temp * (lastSimTime - minTime) / (maxTime - minTime) / 20  \n",
    "                else:\n",
    "                    train_output = np.concatenate((train_output , discount_rewards(np.array(reward)) * temp * (lastSimTime - minTime) / (maxTime - minTime) / 20  ), axis=0)\n",
    "                print(lllll)\n",
    "        Learn()\n",
    "\n",
    "# ================================================================================================================\n",
    "        # if reward < 0:\n",
    "        #     train_input.append(np.array(np.concatenate((state,action), axis=0) ))\n",
    "        #     train_output.append(np.array([0]))\n",
    "        #     state = negative8(state)\n",
    "        #     action = negative5(action)\n",
    "    # конец испытаний\n",
    "    print(\"=YYEEESS=\")\n",
    "    print(np.size(train_input,axis = 0),np.size(train_input,axis = 1))\n",
    "    print(np.size(train_output,axis = 0),np.size(train_output,axis = 1))\n",
    "#     model_sa_q.fit(train_input,train_output,epochs = 20,batch_size = 64)\n",
    "# # ================================================================================================================\n",
    "#     print(\"Обучение sa сетки:\")  \n",
    "#     train_input = []\n",
    "#     train_output = []\n",
    "#     state = np.random.random_sample((50,1,n_input))\n",
    "#     for i in range(50):\n",
    "#         fin_q = 0\n",
    "#         fin_state = state[i]\n",
    "#         for j in range(20):\n",
    "#             action = np.random.random_sample((1,n_output))\n",
    "#             q = model_sa_q.predict( np.array(np.concatenate((fin_state,action), axis=1)) )[0][0]\n",
    "#             if q > fin_q:\n",
    "#                 fin_q = q\n",
    "#                 fin_action = action\n",
    "#         train_input.append(fin_state[0])\n",
    "#         train_output.append(fin_action[0])\n",
    "\n",
    "#     train_input = np.array(train_input)\n",
    "#     train_output = np.array(train_output)\n",
    "#     model_s_a.fit(train_input , train_output ,epochs = 10,batch_size = 32)\n",
    "# # TEST============================================================================================================\n",
    "#     shotTimeArray = []\n",
    "#     shotSArray = []\n",
    "#     for m in range(10):\n",
    "#         def Learn():\n",
    "#             import SimLibB0.b0RemoteApi as b0RemoteApi    \n",
    "#             global dtSimTime\n",
    "#             global lastSimTime\n",
    "#             global startFlag\n",
    "#             global doNextStep\n",
    "#             global stop\n",
    "#             temp = exp\n",
    "#             if exp > 50:\n",
    "#                 temp = 50\n",
    "#             if random.random() < (1 - temp/50 * 0.5):\n",
    "#                 key = \"sin\"\n",
    "#                 print(\"sin\")\n",
    "#             else:\n",
    "#                 key = \"neuron\"\n",
    "#                 print(\"neuron\")\n",
    "#             dtSimTime = 0.025\n",
    "#             lastSimTime = 0\n",
    "#             startFlag = True\n",
    "#             with b0RemoteApi.RemoteApiClient('b0RemoteApi_pythonClient'+str(exp*50 + j),'b0RemoteApi_q_robot') as client:\n",
    "#                 doNextStep = True\n",
    "#                 stop = False\n",
    "#             # -------------------------------------------------------------------------------------------------------\n",
    "#                 def simulationStepStarted(msg):\n",
    "#                     simTime = msg[1][b'simulationTime']\n",
    "#                     global legs\n",
    "#                     global body \n",
    "\n",
    "#                     state = np.array([])\n",
    "#                     for i in range(0,4):\n",
    "#                         state  = np.append(state, (legs[i].pos + 10) / (40) + 0.5)\n",
    "#                         state  = np.append(state, legs[i].vel / (600 * 2) + 0.5)\n",
    "#                     for i in range(4,8):\n",
    "#                         state  = np.append(state, (legs[i].pos + 20) / (40) + 0.5 )\n",
    "#                         state  = np.append(state, legs[i].vel / (600 * 2) + 0.5)\n",
    "#                     state = np.append(state, [body.pos[0] / 0.1,body.pos[5] / 0.6])\n",
    "#                     jointAction = simVerify(simTime,state,client)\n",
    "                    \n",
    "#             # -------------------------------------------------------------------------------------------------------\n",
    "#                 def simulationStepDone(msg):\n",
    "#                     simTime = msg[1][b'simulationTime']\n",
    "#                     global stop\n",
    "#                     global body\n",
    "#                     r,stop = Reward(simTime,body.pos)\n",
    "\n",
    "#                     global dtSimTime\n",
    "#                     global lastSimTime\n",
    "#                     dtSimTime = simTime - lastSimTime\n",
    "#                     lastSimTime = simTime\n",
    "#                     global doNextStep\n",
    "#                     doNextStep=True\n",
    "#             # -------------------------------------------------------------------------------------------------------\n",
    "#                 def init_hand():\n",
    "#                     global body\n",
    "#                     errHand,bodyHand = client.simxGetObjectHandle(\"RobotTyapa\",client.simxServiceCall())\n",
    "#                     body = Body(bodyHand)\n",
    "#                     # привязываем обработчик для чтения получения данных о роботе\n",
    "#                     client.simxGetObjectPose(body.Hand,-1,client.simxDefaultSubscriber(body.eventPos))\n",
    "#                     global legs\n",
    "#                     legs = []\n",
    "#                     for leg in legs_name:\n",
    "#                         errHand,legHand = client.simxGetObjectHandle(leg,client.simxServiceCall())\n",
    "#                         legs.append(Leg(legHand))\n",
    "#                     # привязываем обработчик для чтения получения данных о движках\n",
    "#                     for leg in legs:\n",
    "#                         client.simxGetJointPosition(leg.Hand,client.simxDefaultSubscriber(leg.eventPos))\n",
    "#             # -------------------------------------------------------------------------------------------------------\n",
    "#                 client.simxSynchronous(True)\n",
    "#                 client.simxGetSimulationStepStarted(client.simxDefaultSubscriber(simulationStepStarted))\n",
    "#                 client.simxGetSimulationStepDone(client.simxDefaultSubscriber(simulationStepDone))\n",
    "#                 client.simxStartSimulation(client.simxDefaultPublisher())\n",
    "#                 init_hand()\n",
    "#                 startTime = time.time()\n",
    "#                 while not(stop): \n",
    "#                     if doNextStep:\n",
    "#                         doNextStep = False\n",
    "#                         client.simxSynchronousTrigger()\n",
    "#                     client.simxSpinOnce()\n",
    "#                 client.simxStopSimulation(client.simxDefaultPublisher())\n",
    "#                 global body\n",
    "#                 global legs\n",
    "#                 if body.pos[1] < 0:\n",
    "#                     temp = 0\n",
    "#                 else:\n",
    "#                     temp = body.pos[1]\n",
    "                \n",
    "#         Learn()\n",
    "#         shotTimeArray.append(lastSimTime)\n",
    "#         shotSArray.append(body.pos)    \n",
    "#     timeArray.append(shotTimeArray)\n",
    "#     sArray.append(shotSArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 32-bit",
   "language": "python",
   "name": "python37132bit774e41f0292e48fb86ba2f8c46bd4c01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
